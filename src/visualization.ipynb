{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dynamicSceneGenerator import DynamicSceneGenerator\n",
    "from visualize import visualize, visualize_camera_gif, visualize_projections, visualize_bounding_boxes\n",
    "from datatypes.virtualCamera import VirtualCamera\n",
    "\n",
    "# Might need to pip install json, json_stream, as they are not default libraries\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_camera_position_WRF(focal_length, width_of_sensor, largest_radius, path_centre, camera_height):\n",
    "    angle_of_view = 2*np.arctan(width_of_sensor/(2*focal_length)) # In radians\n",
    "    d = largest_radius/np.tan(angle_of_view/2)\n",
    "    # Assume camera parallel to x axis and always pointing towards the centre of the path circle\n",
    "    x = d+path_centre[0]\n",
    "    y = path_centre[1]\n",
    "    z = camera_height\n",
    "    return np.array([x,y,z])\n",
    "\n",
    "def calculate_camera_pitch(camera_position):\n",
    "    alpha = np.arctan(camera_position[2]/camera_position[0]) # arctan(height/distance)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_place_simple_legacy_camera(largest_radius, path_centre): # This should maybe get a better name, and should be moved somewhere?\n",
    "    '''\n",
    "    Function for placing a Simple legacy photo camera in the dynamic scene\n",
    "    '''\n",
    "    # NB! Make sure everything is in meters\n",
    "    focal_length = 50*10**-3\n",
    "    image_bounds = (3600, 2400) # Pixels (x,y)\n",
    "    film_size = (36*10**-3, 24*10**-3)\n",
    "    px = film_size[0]/image_bounds[0]\n",
    "    py = film_size[1]/image_bounds[1]\n",
    "    principal_point = (image_bounds[0]/2,image_bounds[1]/2)\n",
    "    width_of_sensor = 36*10**-3 # Width of sensor\n",
    "    camera_height = 60 # metre\n",
    "\n",
    "    position_WRF = calculate_camera_position_WRF(focal_length, width_of_sensor, largest_radius, path_centre, camera_height)\n",
    "    roll = np.pi/20\n",
    "    yaw = np.pi\n",
    "    pitch = calculate_camera_pitch(position_WRF)\n",
    "    \n",
    "    camera = VirtualCamera(position_WRF, roll, yaw, pitch, focal_length, px, py, principal_point, image_bounds)\n",
    "\n",
    "    return camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_all_points(camera, vessels):\n",
    "    all_projected_points = {}\n",
    "    for t in vessels[0].get_track().get_time_stamps():\n",
    "        points = [vessel.calculate_3D_cornerpoints(t) for vessel in vessels]\n",
    "        projected_points = [camera.project_points(vessel_points) for vessel_points in points]\n",
    "        all_projected_points[t] = projected_points\n",
    "    return all_projected_points\n",
    "\n",
    "# Where should we save the projected points? A separate class, in the dynamic scene?\n",
    "# And also the functions in this file should be in a separate class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bound_boxes(projected_points):\n",
    "    bbs = {}\n",
    "    for vesselID, vessel_dict in projected_points.items():\n",
    "        x_vals = list(map(lambda v : v['x'], vessel_dict.values()))\n",
    "        y_vals = list(map(lambda v : v['y'], vessel_dict.values()))\n",
    "        max_x = np.max(x_vals)\n",
    "        min_x = np.min(x_vals)\n",
    "        max_y = np.max(y_vals)\n",
    "        min_y = np.min(y_vals)\n",
    "        width = max_x-min_x\n",
    "        height = max_y - min_y\n",
    "        center = [min_x+width/2, min_y+height/2]\n",
    "        #bb = np.array([[min_x,min_y],[min_x, max_y],[max_x, max_y],[max_x, min_y]]) \n",
    "        bb = {'centre': {'x': center[0], 'y': center[1]}, 'height': height, 'width': width} \n",
    "        # Make sure these are in the correct order as in master thesis\n",
    "        bbs[vesselID] = bb\n",
    "    return bbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_bbs(all_projected_points):\n",
    "    all_bbs = {}\n",
    "    for t in all_projected_points.keys():\n",
    "        all_bbs[t]=create_bound_boxes(all_projected_points[t])\n",
    "    return all_bbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_json(path, dict):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, 'w+') as f:\n",
    "        json.dump(dict, f, indent = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracks_to_json(vessels):\n",
    "    # NB! Assumes all vessels have the same timestamp\n",
    "    all_tracks = {key: {vessel.id: vessel.get_track_dict()[key] for vessel in vessels} for key in vessels[0].get_track_dict().keys()}\n",
    "    arr = os.listdir('./simulations/')\n",
    "    timestamp = 0 if not arr else int(arr[-1])+1\n",
    "    filename = f'./simulations/{timestamp}/tracks.json'\n",
    "    dict_to_json(filename, all_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dynamic scene with random tracks\n",
    "dsg = DynamicSceneGenerator()\n",
    "dsg.set_random_vessels(6)\n",
    "dsg.generate_random_tracks()\n",
    "vessels = dsg.get_vessels()\n",
    "tracks_to_json(vessels)\n",
    "# visualize(vessels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = create_and_place_simple_legacy_camera(dsg.get_larges_radius(), dsg.get_path_centre())\n",
    "# visualize_camera_gif(camera, vessels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projected_points = project_all_points(camera, vessels)\n",
    "# visualize_projections(all_projected_points, camera.image_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All projected points will probably be on a different format. Did this to get a file.\n",
    "projected_points_dict = {key: {vessels[i].id: {x: {'x': all_projected_points[key][i][x][0], 'y': all_projected_points[key][i][x][1], 'z': all_projected_points[key][i][x][2]} for x in range(len(all_projected_points[key][i]))} for i in range(len(all_projected_points[key]))} for key in all_projected_points.keys()}\n",
    "filename = f'./simulations/0/projectedPoints.json'\n",
    "dict_to_json(filename, projected_points_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bbs = create_all_bbs(projected_points_dict)\n",
    "filename = f'./simulations/0/boundingBoxes.json'\n",
    "dict_to_json(filename, all_bbs)\n",
    "\n",
    "# With points in BBs\n",
    "visualize_bounding_boxes(all_bbs, camera.image_bounds, projected_points=projected_points_dict, show_projected_points=True)\n",
    "# Without\n",
    "#visualize_bounding_boxes(all_bbs, camera.image_bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vessel0': {'centre': [2624.474646311678, 1426.415734021733],\n",
       "  'height': 224.94932676309872,\n",
       "  'width': 90.47097507569742},\n",
       " 'vessel1': {'centre': [911.4188280344054, 1087.3509865672036],\n",
       "  'height': 38.92808796325062,\n",
       "  'width': 64.38445007618543},\n",
       " 'vessel2': {'centre': [2647.9428295021403, 1456.245269432893],\n",
       "  'height': 51.80658335462863,\n",
       "  'width': 60.92677726126658},\n",
       " 'vessel3': {'centre': [2136.5624365201575, 1355.7729371241148],\n",
       "  'height': 218.85866726304903,\n",
       "  'width': 155.9887533458732},\n",
       " 'vessel4': {'centre': [2600.6073507978085, 1426.4620209883938],\n",
       "  'height': 49.65448359449124,\n",
       "  'width': 66.32634902290283},\n",
       " 'vessel5': {'centre': [1991.3573576602466, 1349.3025596772604],\n",
       "  'height': 186.47324352368378,\n",
       "  'width': 432.5462304735818}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bbs[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](gifs/dynamicSceneExample.gif \"Dynamic scene\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](gifs/camera_position.gif \"Camera scene\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](gifs/projected_points.gif \"Projected scene\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](gifs/boundingBoxes.gif \"Projected scene\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('myvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd9570bf49f9b952fb29daa244b5c8b5b40ff513774df97d00f859d7a650f70e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
