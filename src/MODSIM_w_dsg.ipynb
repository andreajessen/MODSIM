{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "from utils import find_path_to_next_simulation\n",
    "from MODSIM import initialize_dynamic_scene_with_random_tracks, perform_time_steps, create_and_place_simple_legacy_camera, calculate_start_state\n",
    "from errorGenerator import ErrorGenerator\n",
    "from datatypes.cameraRig import CameraRig\n",
    "from datatypes.virtualCamera import VirtualCamera\n",
    "from datatypes.conditionState import ConditionState\n",
    "\n",
    "from visualize import visualize_projections_json_mov, visualize_annotations_json, visualize_camera_pose_in_dsg_mov, visualize_dynamic_scene_mov, visualize_detections_json, visualize_detections_multiple_cameras, visualize_annotations_multiple_cameras, visualize_projections_multiple_cameras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAVE_MOTION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera types: 'STATIC_LEGACY', 'DYNAMIC'\n",
    "STATIC_LEGACY = 'STATIC_LEGACY'\n",
    "DYNAMIC = 'DYNAMIC'\n",
    "DYNAMIC_CORAL_CAMERA = 'DYNAMIC_CORAL_CAMERA'\n",
    "ZED ='ZED'\n",
    "MID = 'MID'\n",
    "LEFT = 'LEFT'\n",
    "RIGHT = 'RIGHT'\n",
    "\n",
    "\n",
    "\n",
    "CAMERA_TYPES = [ZED]\n",
    "CAMERA_PLACEMENTS = [MID]\n",
    "# Roll, yaw, pitch\n",
    "ORIENTATION = [[0, 0, np.pi/200], [0, 0, np.pi/200]]\n",
    "\n",
    "VESSEL_TO_PLACE_CAMERA_ON = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_CONFIG_PATH = 'detector_stats_config.yaml'\n",
    "NUMBER_OF_VESSELS = 10\n",
    "WRITE_TO_JSON = True\n",
    "T_START = 0\n",
    "T_END = 500\n",
    "VISUALIZE=True\n",
    "MIN_NUM_VESSELS = 1\n",
    "ANNOTATION_MODE = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_DISTURBANCE  = 0\n",
    "SMALL_DISTURBANCE  = 1\n",
    "MEDIUM_DISTURBANCE  = 2\n",
    "LARGE_DISTURBANCE  = 4\n",
    "HUGE_DISTURBANCE  = 6\n",
    "\n",
    "\n",
    "WAVE_INDUCED_CAMERA_DISTURBANCE_COEF = MEDIUM_DISTURBANCE  # int from 0-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./simulations/10/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find folder to save simultation trial to\n",
    "simulation_folder = find_path_to_next_simulation()\n",
    "simulation_folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize MODSIM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define condition based confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numb_states = 4\n",
    "\n",
    "with open('detector_stats_config.yaml', 'r') as stream:\n",
    "            config = yaml.safe_load(stream)\n",
    "if config.get('detectionConditions'):\n",
    "    start_state = calculate_start_state(config.get('detectionConditions'), numb_states)\n",
    "else:\n",
    "    # Default is excellent weather\n",
    "    start_state = calculate_start_state({'precipitation': 0, 'fog': 0, 'wind': 0, 'darkness': 0}, numb_states)\n",
    "\n",
    "CM = config.get('confusionMatrix')\n",
    "CM0 = {'FN': round(CM['FN']/3,3), 'FP': round(CM['FP']/3,3), 'TP': 1-round(CM['FN']/3,3), 'TN': 1 - round(CM['FP']/3,3)}\n",
    "CM1 = {'FN': round(CM['FN']/1.5,3), 'FP': round(CM['FP']/1.5,3), 'TP': 1-round(CM['FN']/1.5,3), 'TN': 1 - round(CM['FP']/1.5,3)}\n",
    "CM2 = {'FN': round(min(CM['FN']*1.5, 0.99),3), 'FP': round(min(CM['FP']*1.5, 0.99),3), 'TP': 1-round(min(CM['FN']*1.5, 0.99),3), 'TN': 1 - round(min(CM['FP']*1.5, 0.99),3)}\n",
    "CM3 = {'FN': round(min(CM['FN']*3, 0.99),3), 'FP': round(min(CM['FP']*3, 0.99),3), 'TP': 1-round(min(CM['FN']*3, 0.99),3), 'TN': 1 - round(min(CM['FP']*3, 0.99),3)}\n",
    "\n",
    "\n",
    "TM =  np.array([[0.996, 0.0017, 0.0006, 0.0006],[0.0022, 0.996, 0.0017, 0.0012],[0.0012, 0.0017, 0.996, 0.0022],[0.0006, 0.0006, 0.0017, 0.996]])\n",
    "states = {0: ConditionState('Excellent conditions', 0, CM0), 1: ConditionState('Good conditions', 1, CM1), 2: ConditionState('Poor conditions', 2, CM2), 3: ConditionState('Terrible conditions', 3, CM3)}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update class-based confusion matrix in the condition states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_label = config.get('confusionMatrixLabels')\n",
    "false_positives_label = config.get('falsePositives')\n",
    "\n",
    "cms_label = {}\n",
    "state_multiplicate = [1/3, 1/1.5, 1.5, 3]\n",
    "if CM_label:\n",
    "    for s in range(numb_states):\n",
    "        s_factor = state_multiplicate[s]\n",
    "        all_new_values = {}\n",
    "        for i, label in enumerate(CM_label.keys()):\n",
    "            values = CM_label[label]\n",
    "            drop_out = 1-sum(values)\n",
    "            incorrect_detection = sum([e for indx, e in enumerate(values) if indx != i])+drop_out\n",
    "            new_values = []\n",
    "            for v in range(len(values)):\n",
    "                if v == i:\n",
    "                    new_values.append(round(1-min(incorrect_detection*s_factor,0.99), 3))\n",
    "                else:\n",
    "                    new_values.append(round(min(values[v]*s_factor, 0.99), 3))\n",
    "            all_new_values[label] = new_values\n",
    "        \n",
    "        states[s].set_confusion_matrix_labels(all_new_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize dynamic scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic scene\n",
    "dsg = initialize_dynamic_scene_with_random_tracks(NUMBER_OF_VESSELS, writeToJson=WRITE_TO_JSON, path=simulation_folder)\n",
    "vessels = dsg.get_vessels()\n",
    "\n",
    "## Error generator\n",
    "errorGenerator = ErrorGenerator(ERROR_CONFIG_PATH, temporal_model=True, states=states, start_state=start_state, transition_matrix=TM)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_vcf(vessel, placement):\n",
    "    if placement == LEFT:\n",
    "        return np.array([vessel.get_length()/2, vessel.get_beam()/2, vessel.get_air_draft()/2])\n",
    "    elif placement == RIGHT:\n",
    "        return np.array([vessel.get_length()/2, -vessel.get_beam()/2, vessel.get_air_draft()/2])\n",
    "    else:\n",
    "        # Default MID\n",
    "        return np.array([vessel.get_length()/2, 0, vessel.get_air_draft()/2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = {}\n",
    "for cameraID, cameraType in enumerate(CAMERA_TYPES):\n",
    "    if cameraType == STATIC_LEGACY:\n",
    "        ##### Static Camera #####\n",
    "        # Create simple legacy camera and place it in the dynamic scene\n",
    "        camera = create_and_place_simple_legacy_camera(dsg.get_larges_radius(), dsg.get_path_centre())\n",
    "\n",
    "        ########################### OBS  ###################################################### \n",
    "        # If there is a static camera, there can only be one camera in the camera rig\n",
    "        ####################################################################################### \n",
    "        cameras = {}\n",
    "        cameras[0] = camera\n",
    "        vessel = None\n",
    "        break\n",
    "\n",
    "    elif cameraType == DYNAMIC:\n",
    "        ###### Dynamic Camera ######\n",
    "        focal_length = 50*10**-3\n",
    "        image_bounds = (3600, 2400) # Pixels (x,y)\n",
    "        film_size = (36*10**-3, 24*10**-3)\n",
    "        px = film_size[0]/image_bounds[0]\n",
    "        py = film_size[1]/image_bounds[1]\n",
    "        principal_point = (image_bounds[0]/2,image_bounds[1]/2)\n",
    "        width_of_sensor = 36*10**-3 # Width of sensor\n",
    "        \n",
    "        # Pose\n",
    "        roll_vcf = ORIENTATION[cameraID][0]\n",
    "        yaw_vcf = ORIENTATION[cameraID][1]\n",
    "        pitch_vcf = ORIENTATION[cameraID][2]\n",
    "        vessel = vessels[VESSEL_TO_PLACE_CAMERA_ON] # Must be the same for al cameras in the camera rig\n",
    "        pos_vcf = get_pos_vcf(vessel, CAMERA_PLACEMENTS[cameraID])\n",
    "\n",
    "\n",
    "        camera = VirtualCamera(focal_length, px, py, principal_point, image_bounds)\n",
    "        camera.place_camera_on_vessel(pos_vcf, roll_vcf, pitch_vcf, yaw_vcf)\n",
    "    elif cameraType == DYNAMIC_CORAL_CAMERA:\n",
    "        # https://www.tme.eu/Document/3e25990c825098a96a442d65b17c6632/CORAL-CAMERA-5MP.pdf\n",
    "        ###### Dynamic Camera ######\n",
    "        # Intrinsics\n",
    "        # NB! Make sure everything is in meters\n",
    "        focal_length = 2.5*10**-3\n",
    "        image_bounds = (2592, 1933) # Pixels (x,y)\n",
    "        #film_size = (1.4*10**-3, 1.4*10**-3)\n",
    "        px = 1.4*10**-6\n",
    "        py = 1.4*10**-6\n",
    "        #px = 2*10**-6\n",
    "        #py = 2*10**-6\n",
    "        principal_point = (image_bounds[0]/2,image_bounds[1]/2)\n",
    "        width_of_sensor = 36*10**-3 # Width of sensor\n",
    "\n",
    "        # Pose\n",
    "        roll_vcf = ORIENTATION[cameraID][0]\n",
    "        yaw_vcf = ORIENTATION[cameraID][1]\n",
    "        pitch_vcf = ORIENTATION[cameraID][2]\n",
    "        vessel = vessels[VESSEL_TO_PLACE_CAMERA_ON]\n",
    "        pos_vcf = get_pos_vcf(vessel, CAMERA_PLACEMENTS[cameraID])\n",
    "\n",
    "\n",
    "        camera = VirtualCamera(focal_length, px, py, principal_point, image_bounds)\n",
    "        camera.place_camera_on_vessel(pos_vcf, roll_vcf, pitch_vcf, yaw_vcf)\n",
    "    elif cameraType == ZED:\n",
    "        # Intrinsics\n",
    "        # NB! Make sure everything is in meters\n",
    "        focal_length = 2.8*10**-3\n",
    "        image_bounds = (2688, 1520) # Pixels (x,y)\n",
    "        #film_size = (1.4*10**-3, 1.4*10**-3)\n",
    "        fx = 1404.2700\n",
    "        fy = 1404.8199\n",
    "        px = focal_length/fx\n",
    "        py = focal_length/fy\n",
    "        #px = 2*10**-6\n",
    "        #py = 2*10**-6\n",
    "        principal_point = (1110.9700,614.7650)\n",
    "\n",
    "        # Pose\n",
    "        roll_vcf = ORIENTATION[cameraID][0]\n",
    "        yaw_vcf = ORIENTATION[cameraID][1]\n",
    "        pitch_vcf = ORIENTATION[cameraID][2]\n",
    "        vessel = vessels[VESSEL_TO_PLACE_CAMERA_ON]\n",
    "        pos_vcf = get_pos_vcf(vessel, CAMERA_PLACEMENTS[cameraID])\n",
    "\n",
    "\n",
    "        camera = VirtualCamera(focal_length, px, py, principal_point, image_bounds)\n",
    "        camera.place_camera_on_vessel(pos_vcf, roll_vcf, pitch_vcf, yaw_vcf)\n",
    "    # elif cameraType == OTHER TYPES:\n",
    "    \n",
    "    cameras[cameraID] = camera\n",
    "\n",
    "camera_rig = CameraRig(cameras, vessel, wave_induced_camera_disturbance_coef=WAVE_INDUCED_CAMERA_DISTURBANCE_COEF)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pps, bbs, eBBs = perform_one_time_step_class(dsg, errorGenerator, camera_rig, 0, writeToJson=WRITE_TO_JSON, path=simulation_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pps, bbs, eBBs = perform_time_steps(T_START, T_END, dsg, errorGenerator, camera_rig, annotation_mode=ANNOTATION_MODE, writeToJson=WRITE_TO_JSON, path=simulation_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading projections from json\n",
      "Visualizing projections\n",
      "Moviepy - Building video ./simulations/10/projectedPoints_C0.mp4.\n",
      "Moviepy - Writing video ./simulations/10/projectedPoints_C0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./simulations/10/projectedPoints_C0.mp4\n",
      "Moviepy - Building video ./simulations/10/detections_C0.mp4.\n",
      "Moviepy - Writing video ./simulations/10/detections_C0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  21%|██▏       | 106/498 [00:26<03:22,  1.93it/s, now=None]"
     ]
    }
   ],
   "source": [
    "# Visualize from json files\n",
    "if VISUALIZE:\n",
    "    #x_y_lim = dsg.get_larges_radius() + 1050\n",
    "    x_y_lim = 2000\n",
    "    if STATIC_LEGACY in CAMERA_TYPES:\n",
    "        x_y_lim = None\n",
    "    pps_paths = {cameraID: os.path.join(simulation_folder, f'projectedPoints_C{cameraID}.json') for cameraID in cameras.keys()}\n",
    "    annots_paths = {cameraID: os.path.join(simulation_folder, f'annotations_C{cameraID}.json') for cameraID in cameras.keys()}\n",
    "    detections_paths = {cameraID: os.path.join(simulation_folder, f'detections_C{cameraID}.json') for cameraID in cameras.keys()}\n",
    "    image_bounds = {cameraID: camera_rig.cameras[cameraID].image_bounds for cameraID in cameras.keys()}\n",
    "    cameraIDs = list(cameras.keys())\n",
    "\n",
    "    #visualize_dynamic_scene_mov(vessels, folder_path=simulation_folder)\n",
    "    #visualize_camera_pose_in_dsg_mov(camera_rig, vessels, folder_path=simulation_folder, y_x_lim=x_y_lim)\n",
    "    visualize_projections_multiple_cameras(cameraIDs, pps_paths, image_bounds, camera_rig.horizon, folder_path=simulation_folder, display_when_min_vessels=MIN_NUM_VESSELS)\n",
    "    #visualize_annotations_multiple_cameras(cameraIDs, annots_paths, image_bounds, horizons=camera_rig.horizon, folder_path=simulation_folder, display_when_min_vessels=MIN_NUM_VESSELS)\n",
    "    visualize_detections_multiple_cameras(cameraIDs, detections_paths, image_bounds, horizons=camera_rig.horizon, show_annotations=True, annotations_paths=annots_paths, folder_path=simulation_folder, display_when_min_vessels=MIN_NUM_VESSELS, temporal_state_history=errorGenerator.temporal_model.previous_states, temporal_state_names=errorGenerator.temporal_model.state_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd9570bf49f9b952fb29daa244b5c8b5b40ff513774df97d00f859d7a650f70e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
